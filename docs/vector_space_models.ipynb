{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vector Space Models\n",
    "\n",
    "This chapter discusses computational models to represent text in vector spaces.\n",
    "\n",
    "* [Preparation](#Preparation)\n",
    "* [Bag-of-Words](#Bag-of-Words)\n",
    "* [Frequency Counts](#Frequency-Counts)\n",
    "* [Exercise 1](#Exercise-1)\n",
    "* [TF-IDF](#TF-IDF)\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "* [Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)\n",
    "* [Bag-of-Words Model](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [TF-IDF](https://en.wikipedia.org/wiki/Tfâ€“idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Download [`aesopfables.json`](https://github.com/emory-courses/computational-linguistics/blob/master/docs/res/aesopfables.json) and read the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jdchoi/workspace/cs329/venv/lib/python3.10/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jdchoi/workspace/cs329/venv/lib/python3.10/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jdchoi/workspace/cs329/venv/lib/python3.10/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jdchoi/workspace/cs329/venv/lib/python3.10/site-packages (from requests) (2.0.10)\n",
      "Installing collected packages: requests\n",
      "Successfully installed requests-2.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "import requests\n",
    "\n",
    "def download(remote_addr: str, local_addr: str):\n",
    "    r = requests.get(remote_addr)\n",
    "    fin = open(local_addr, 'wb')\n",
    "    fin.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`requests`](https://requests.readthedocs.io/en/master/user/quickstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesop_link = 'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/docs/res/aesopfables.json'\n",
    "aesop_file = 'res/aesopfables.json'\n",
    "download(aesop_link, aesop_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure which directory `aesopfables.json` is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "Androcles\n",
      "The Ant and the Chrysalis\n",
      "The Ant and the Dove\n",
      "The Ants and the Grasshopper\n",
      "The Apes and the Two Travelers\n",
      "The Ass and His Driver\n",
      "The Ass and His Masters\n",
      "The Ass and His Purchaser\n",
      "The Ass and His Shadow\n",
      "The Ass and the Charger\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "fables = json.load(open(aesop_file))\n",
    "\n",
    "print(len(fables))\n",
    "for fable in fables[:10]: print(fable['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "Let there be a giant bag that can hold all unique words in the world.\n",
    "Then, each token in a text such as \"*Jinho Choi is a professor at Emory University .*\" can be inserted to the bag as follows:\n",
    "\n",
    "<img src=\"res/bow.jpg\" width=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "This bag can be represented by a vector of which every dimension stands for a unique token in the world.\n",
    "All dimensions are initialized to `0`, except for the ones representing tokens in the input text, which are assigned with `1`:\n",
    "\n",
    "<img src=\"res/vsm.jpg\" width=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total dimension of this vector?\n",
    "* Does this vector correctly represent the original text (anything missing)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words can be implemented by a dictionary (representing a sparse vector), where the key is a term in the text and its value is always `1`.\n",
    "The value of every other term that does not appear in the document is assumed to be `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {'Jinho': 1, 'Choi': 1, 'is': 1, 'a': 1, 'professor': 1, 'at': 1, 'Emory': 1, 'University': 1, '.': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Counts\n",
    "\n",
    "Consider the following two documents:\n",
    "\n",
    "```\n",
    "D1: John bought a car . The car was fancy .\n",
    "D2: Mary liked the car .  John gave it to Mary .\n",
    "```\n",
    "\n",
    "A **term frequency** (`tf`) is the number of occurrences of a specific term in a specific document:\n",
    "\n",
    "```\n",
    "tf(John, D1) = 1\n",
    "tf(John, D2) = 1\n",
    "tf(Mary, D2) = 2\n",
    "```\n",
    "\n",
    "A **document frequency** (`df`) is the number of documents containing a specific term:\n",
    "\n",
    "```\n",
    "df(John) = 2\n",
    "df(John) = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `term_frequencies()` that takes `fables` above and returns a dictionary where each key-value pair represents the source and term frequencies of the corresponding document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict\n",
    "\n",
    "def term_frequencies(fables) -> Dict[str, Counter]:\n",
    "    def key(t): return t[t.rfind('&')+1:]\n",
    "    return {key(fable['source']): Counter(fable['tokens'].split()) for fable in fables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 20, 'and': 19, ',': 18, 'to': 13, '.': 12, 'his': 9, 'Lion': 9, 'Androcles': 8, 'was': 8, 'he': 7, 'him': 6, 'came': 4, 'a': 4, 'slave': 3, 'from': 3, 'out': 3, 'all': 3, 'of': 3, 'forest': 2, 'As': 2, 'upon': 2, 'turned': 2, 'that': 2, 'up': 2, 'near': 2, 'paw': 2, 'which': 2, 'thorn': 2, 'had': 2, 'into': 2, 'who': 2, 'soon': 2, 'like': 2, 'dog': 2, 'But': 2, 'The': 2, 'Emperor': 2, 'let': 2, 'loose': 2, 'as': 2, 'A': 1, 'named': 1, 'once': 1, 'escaped': 1, 'master': 1, 'fled': 1, 'wandering': 1, 'about': 1, 'there': 1, 'lying': 1, 'down': 1, 'moaning': 1, 'groaning': 1, 'At': 1, 'first': 1, 'flee': 1, 'but': 1, 'finding': 1, 'did': 1, 'not': 1, 'pursue': 1, 'back': 1, 'went': 1, 'put': 1, 'swollen': 1, 'bleeding': 1, 'found': 1, 'huge': 1, 'got': 1, 'it': 1, 'causing': 1, 'pain': 1, 'He': 1, 'pulled': 1, 'bound': 1, 'able': 1, 'rise': 1, 'lick': 1, 'hand': 1, 'Then': 1, 'took': 1, 'cave': 1, 'every': 1, 'day': 1, 'used': 1, 'bring': 1, 'meat': 1, 'live': 1, 'shortly': 1, 'afterwards': 1, 'both': 1, 'were': 1, 'captured': 1, 'sentenced': 1, 'be': 1, 'thrown': 1, 'after': 1, 'latter': 1, 'been': 1, 'kept': 1, 'without': 1, 'food': 1, 'for': 1, 'several': 1, 'days': 1, 'Court': 1, 'see': 1, 'spectacle': 1, 'led': 1, 'middle': 1, 'arena': 1, 'Soon': 1, 'den': 1, 'rushed': 1, 'bounding': 1, 'roaring': 1, 'towards': 1, 'victim': 1, 'recognised': 1, 'friend': 1, 'fawned': 1, 'licked': 1, 'hands': 1, 'friendly': 1, 'surprised': 1, 'at': 1, 'this': 1, 'summoned': 1, 'told': 1, 'whole': 1, 'story': 1, 'Whereupon': 1, 'pardoned': 1, 'freed': 1, 'native': 1})\n"
     ]
    }
   ],
   "source": [
    "tfs = term_frequencies(fables)\n",
    "print(tfs['Androcles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Let us define the function `document_frequencies()` that takes `fables` and returns a dictionary where each key-value pair represents a term and its document frequency:\n",
    "\n",
    "```python\n",
    "def document_frequencies(fables) -> Dict[str, int]:\n",
    "    # To be filled\n",
    "    return dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 5\n",
      ". 356\n",
      ", 355\n",
      "the 350\n",
      "and 344\n",
      "to 337\n",
      "a 335\n",
      "of 313\n",
      "\" 280\n",
      "in 275\n",
      "his 252\n"
     ]
    }
   ],
   "source": [
    "dfs = document_frequencies(fables)\n",
    "print(dfs['Lion'], dfs['lion'])\n",
    "for term, count in sorted(dfs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(term, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [sorted()](https://docs.python.org/3/library/functions.html?highlight=sorted#sorted)\n",
    "* [lambda](https://docs.python.org/3/reference/expressions.html#lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "What are important terms in a document?\n",
    "\n",
    "* High term frequency\n",
    "* low document frequency\n",
    "\n",
    "The $\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d}$ (Term Frequency - Inverse Document Frequency) of a specific term $t$ in a specific document $d \\in D$ is measured as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d} = \\mathrm{tf}_{t,d} \\times \\log\\frac{|D|}{\\mathrm{df}_t}\n",
    "$$\n",
    "\n",
    "Several variations of $\\mathrm{tf}_{t,d}$ have also been proposed using sublinear or normalization:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{wf}_{t,d} &=& \\left\\{\n",
    "\\begin{array}{cl}\n",
    " 1 + \\log\\mathrm{tf}_{t,d} & \\mbox{if $\\textrm{tf}_{t,d} > 0$}\\\\\n",
    " 0 & \\mbox{otherwise}\n",
    "\\end{array}\n",
    "\\right. \\\\\n",
    "\\mathrm{ntf}_{t,d} &=& \\alpha + (1-\\alpha)\\frac{\\mathrm{tf}_{t,d}}{\\mathrm{tf}_{\\mathrm{argmax}({\\mathrm{tf}_{\\forall t, d}}),d}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `tf_idfs()` that takes `fables` and returns a dictionary where the key is a (term, document ID) pair, and the value is its TF-IDF score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def tf_idfs(fables) -> Dict[str, Dict[str, int]]:\n",
    "    tfs = term_frequencies(fables)\n",
    "    dfs = document_frequencies(fables)\n",
    "    out = dict()\n",
    "    D = len(tfs)\n",
    "\n",
    "    for dkey, term_counts in tfs.items():\n",
    "        out[dkey] = {t: tf  / dfs[term] for t, tf in term_counts.items()}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.109514790065465\n"
     ]
    }
   ],
   "source": [
    "tfidfs = tf_idfs(fables)\n",
    "print(tfidfs['Androcles']['Lion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 20\n",
      "and 19\n",
      ", 18\n",
      "to 13\n",
      ". 12\n",
      "his 9\n",
      "Lion 9\n",
      "Androcles 8\n",
      "was 8\n",
      "he 7\n",
      "him 6\n",
      "came 4\n",
      "a 4\n",
      "slave 3\n",
      "from 3\n",
      "out 3\n",
      "all 3\n",
      "of 3\n",
      "forest 2\n",
      "As 2\n"
     ]
    }
   ],
   "source": [
    "    for t, tf in sorted(tfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "        print(t, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 6.910032866812145\n",
      "and 6.564531223471538\n",
      ", 6.21902958013093\n",
      "to 4.491521363427894\n",
      ". 4.146019720087287\n",
      "his 3.109514790065465\n",
      "Lion 3.109514790065465\n",
      "Androcles 2.764013146724858\n",
      "was 2.764013146724858\n",
      "he 2.418511503384251\n",
      "him 2.0730098600436433\n",
      "came 1.382006573362429\n",
      "a 1.382006573362429\n",
      "slave 1.0365049300218216\n",
      "from 1.0365049300218216\n",
      "out 1.0365049300218216\n",
      "all 1.0365049300218216\n",
      "of 1.0365049300218216\n",
      "forest 0.6910032866812145\n",
      "As 0.6910032866812145\n"
     ]
    }
   ],
   "source": [
    "for t, tfidf in sorted(tfidfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(t, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}