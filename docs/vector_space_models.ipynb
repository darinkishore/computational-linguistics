{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Vector Space Models\n",
    "\n",
    "This chapter discusses computational models to represent text in vector spaces.\n",
    "\n",
    "* [Preparation](#Preparation)\n",
    "* [Bag-of-Words](#Bag-of-Words)\n",
    "* [Frequency Counts](#Frequency-Counts)\n",
    "* [Exercise 1](#Exercise-1)\n",
    "* [TF-IDF](#TF-IDF)\n",
    "* [Similarity Metrics](#Similarity-Metrics)\n",
    "\n",
    "## References\n",
    "\n",
    "* [Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)\n",
    "* [Bag-of-Words Model](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf)\n",
    "* [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)\n",
    "* [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Download [`aesopfables.json`](https://github.com/emory-courses/computational-linguistics/blob/master/docs/res/aesopfables.json) and read the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\r\n",
      "\r\n",
      "  • \u001B[36mrequests\u001B[0m\r\n",
      "\r\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\r\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\r\n",
      "\r\n",
      "Nothing to add.\r\n"
     ]
    }
   ],
   "source": [
    "!poetry add requests\n",
    "import requests\n",
    "\n",
    "def download(remote_addr: str, local_addr: str):\n",
    "    r = requests.get(remote_addr)\n",
    "    fin = open(local_addr, 'wb')\n",
    "    fin.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`requests`](https://requests.readthedocs.io/en/master/user/quickstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesop_link = 'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/res/vsm/aesopfables.json'\n",
    "aesop_file = '../res/vsm/aesopfables.json'\n",
    "download(aesop_link, aesop_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure which directory `aesopfables.json` is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "Androcles\n",
      "The Ant and the Chrysalis\n",
      "The Ant and the Dove\n",
      "The Ants and the Grasshopper\n",
      "The Apes and the Two Travelers\n",
      "The Ass and His Driver\n",
      "The Ass and His Masters\n",
      "The Ass and His Purchaser\n",
      "The Ass and His Shadow\n",
      "The Ass and the Charger\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "fables = json.load(open(aesop_file))\n",
    "\n",
    "print(len(fables))\n",
    "for fable in fables[:10]: print(fable['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "Let there be a giant bag that can hold all unique words in the world.\n",
    "Then, each token in a text such as \"*Jinho Choi is a professor at Emory University .*\" can be inserted to the bag as follows:\n",
    "\n",
    "<img src=\"res/bow.jpg\" width=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3416902580.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[38], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    This bag can be represented by a vector of which every dimension stands for a unique token in the world.\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "This bag can be represented by a vector of which every dimension stands for a unique token in the world.\n",
    "All dimensions are initialized to `0`, except for the ones representing tokens in the input text, which are assigned with `1`:\n",
    "\n",
    "<img src=\"res/vsm.jpg\" width=600 align=\"left\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total dimension of this vector?\n",
    "8\n",
    "* Does this vector correctly represent the original text (anything missing)?\n",
    "Order?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words can be implemented by a dictionary (representing a sparse vector), where the key is a term in the text and its value is always `1`.\n",
    "The value of every other term that does not appear in the document is assumed to be `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {'Jinho': 1, 'Choi': 1, 'is': 1, 'a': 1, 'professor': 1, 'at': 1, 'Emory': 1, 'University': 1, '.': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Counts\n",
    "\n",
    "Consider the following two documents:\n",
    "\n",
    "```\n",
    "D1: John bought a car . The car was fancy .\n",
    "D2: Mary liked the car .  John gave it to Mary .\n",
    "```\n",
    "\n",
    "A **term frequency** (`tf`) is the number of occurrences of a specific term in a specific document:\n",
    "\n",
    "```\n",
    "tf(John, D1) = 1\n",
    "tf(John, D2) = 1\n",
    "tf(Mary, D2) = 2\n",
    "```\n",
    "\n",
    "A **document frequency** (`df`) is the number of documents containing a specific term:\n",
    "\n",
    "```\n",
    "df(John) = 2\n",
    "df(John) = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `term_frequencies()` that takes `fables` above and returns a dictionary where each key-value pair represents the source and term frequencies of the corresponding document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict\n",
    "\n",
    "def term_frequencies(fables) -> Dict[str, Counter]:\n",
    "    def key(t): return t[t.rfind('&')+1:]\n",
    "    return {key(fable['source']): Counter(fable['tokens'].split()) for fable in fables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = term_frequencies(fables)\n",
    "print(tfs['Androcles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Let us define the function `document_frequencies()` that takes `fables` and returns a dictionary where each key-value pair represents a term and its document frequency:\n",
    "\n",
    "```python\n",
    "def document_frequencies(fables) -> Dict[str, int]:\n",
    "    # To be filled\n",
    "    return dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 5\n",
      ". 355\n",
      ", 354\n",
      "the 349\n",
      "and 343\n",
      "to 336\n",
      "a 334\n",
      "of 312\n",
      "\" 280\n",
      "in 274\n",
      "his 252\n"
     ]
    }
   ],
   "source": [
    "def document_frequencies(fables) -> Dict[str, int]:\n",
    "    tf = term_frequencies(fables)\n",
    "\n",
    "    doc_freqs = {}\n",
    "    for doc in tf:\n",
    "        for term in dict(tf[doc]):\n",
    "            if term in doc_freqs:\n",
    "                doc_freqs[term] += 1\n",
    "            else:\n",
    "                doc_freqs[term] = 1\n",
    "    return doc_freqs\n",
    "\n",
    "\n",
    "dfs = document_frequencies(fables)\n",
    "print(dfs['Lion'], dfs['lion'])\n",
    "for term, count in sorted(dfs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(term, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [sorted()](https://docs.python.org/3/library/functions.html?highlight=sorted#sorted)\n",
    "* [lambda](https://docs.python.org/3/reference/expressions.html#lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "What are important terms in a document?\n",
    "\n",
    "* High term frequency\n",
    "* low document frequency\n",
    "\n",
    "The $\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d}$ (Term Frequency - Inverse Document Frequency) of a specific term $t$ in a specific document $d \\in D$ is measured as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d} = \\mathrm{tf}_{t,d} \\times \\log\\frac{|D|}{\\mathrm{df}_t}\n",
    "$$\n",
    "\n",
    "Several variations of $\\mathrm{tf}_{t,d}$ have also been proposed using sublinear or normalization:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{wf}_{t,d} &=& \\left\\{\n",
    "\\begin{array}{cl}\n",
    " 1 + \\log\\mathrm{tf}_{t,d} & \\mbox{if $\\textrm{tf}_{t,d} > 0$}\\\\\n",
    " 0 & \\mbox{otherwise}\n",
    "\\end{array}\n",
    "\\right. \\\\\n",
    "\\mathrm{ntf}_{t,d} &=& \\alpha + (1-\\alpha)\\frac{\\mathrm{tf}_{t,d}}{\\mathrm{tf}_{\\mathrm{argmax}({\\mathrm{tf}_{\\forall t, d}}),d}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `tf_idfs()` that takes `fables` and returns a dictionary where the key is a (term, document ID) pair, and the value is its TF-IDF score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def tf_idfs(fables) -> Dict[str, Dict[str, int]]:\n",
    "    tfs = term_frequencies(fables)\n",
    "    dfs = document_frequencies(fables)\n",
    "    out = dict()\n",
    "    D = len(tfs)\n",
    "\n",
    "    for dkey, term_counts in tfs.items():\n",
    "        out[dkey] = {t: tf * math.log(D / dfs[t]) for t, tf in term_counts.items()}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.02357553642621\n"
     ]
    }
   ],
   "source": [
    "tfidfs = tf_idfs(fables)\n",
    "print(tfidfs['Androcles']['Lion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t, score \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mtfs\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAndrocles\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m1\u001B[39m], reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[:\u001B[38;5;241m20\u001B[39m]:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(t, score)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tfs' is not defined"
     ]
    }
   ],
   "source": [
    "for t, score in sorted(tfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Androcles 46.99944584681624\n",
      "Lion 19.02357553642621\n",
      "slave 13.465909109196419\n",
      "Emperor 11.74986146170406\n",
      "paw 9.55263688436784\n",
      "thorn 9.55263688436784\n",
      "loose 8.97727273946428\n",
      "dog 7.858041163593434\n",
      "turned 6.471746802473543\n",
      "forest 5.969117945911732\n",
      "wandering 5.87493073085203\n",
      "moaning 5.87493073085203\n",
      "flee 5.87493073085203\n",
      "bleeding 5.87493073085203\n",
      "sentenced 5.87493073085203\n",
      "arena 5.87493073085203\n",
      "bounding 5.87493073085203\n",
      "recognised 5.87493073085203\n",
      "fawned 5.87493073085203\n",
      "licked 5.87493073085203\n"
     ]
    }
   ],
   "source": [
    "for t, score in sorted(tfidfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics\n",
    "\n",
    "Given two vectors, $X_i = (x_{i1}, \\ldots, x_{in})$ and $X_j = (x_{j1}, \\ldots, x_{jn})$, the **Euclidean distance** between $X_i$ and $X_j$ measures the magnitude between them:\n",
    "\n",
    "$$\n",
    "\\mathrm{Euclidean}(X_i, X_j) = \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{k=1}^n (x_{ik} - x_{jk})^2}\n",
    "$$\n",
    "\n",
    "On the other hand, the **Cosine similarity** measures the angle difference between them:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{Cosine}(X_i, X_j) = \\frac{X_i\\cdot X_j}{\\lVert X_i\\rVert\\lVert X_j\\rVert} = \\frac{\\sum_{\\forall k}(x_{ik} \\cdot x_{jk})}{\\sqrt{\\sum_{\\forall k}(x_{ik})^2} \\cdot \\sqrt{\\sum_{\\forall k}(x_{jk})^2}}\n",
    "$$\n",
    "\n",
    "<img src=\"res/vector_similarities.jpg\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `euclidean(x1, x2)` that takes two sparse vectors, `x1` and `x2`, and returns their Euclidean distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x1: Dict[str, float], x2: Dict[str, float]) -> float:\n",
    "    t = sum(((s1 - x2.get(term, 0)) ** 2 for term, s1 in x1.items()))\n",
    "    t += sum((s2 ** 2 for term, s2 in x2.items() if term not in x1))\n",
    "    return math.sqrt(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.06699680755206\n",
      "61.724694998008005\n"
     ]
    }
   ],
   "source": [
    "tfidfs = tf_idfs(fables)\n",
    "\n",
    "x1 = tfidfs['Androcles']\n",
    "x2 = tfidfs['TheAntandtheChrysalis']\n",
    "x3 = tfidfs['TheAntsandtheGrasshopper']\n",
    "print(euclidean(x1, x2))\n",
    "print(euclidean(x2, x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download another JSON file containing alternative Aesop's fables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/res/vsm/aesopfables-alt.json'\n",
    "file = '../res/vsm/aesopfables-alt.json'\n",
    "download(link, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ant and the Grasshopper\n",
      "The Ass and his Purchaser\n",
      "The Ass and the Lapdog\n",
      "The Ass in the Lion Skin\n",
      "The Belly and the Members\n",
      "The Buffoon and the Countryman\n",
      "The Crow and the Pitcher\n",
      "The Dog in the Manger\n",
      "The Dog and the Shadow\n",
      "The Eagle and the Arrow\n",
      "The Fox and the Crow\n",
      "The Fox and the Goat\n",
      "The Fox and the Grapes\n",
      "The Fox and the Lion\n",
      "The Fox and the Mask\n",
      "The Hare and the Tortoise\n",
      "The Hares and the Frogs\n",
      "The Horse and the Ass\n",
      "The Lion and the Mouse\n",
      "The Lion in Love\n",
      "The Man and the Satyr\n",
      "Mercury and the Woodman\n",
      "The Milkmaid and Her Pail\n",
      "The Old Man and Death\n",
      "The Old Woman and the Wine-Jar\n",
      "The One-Eyed Doe\n",
      "The Peacock and Juno\n",
      "The Rose and the Amaranth\n",
      "The Serpent and the Eagle\n",
      "The Shepherd's Boy\n",
      "The Sick Lion\n",
      "The Town Mouse and the Country Mouse\n",
      "The Trumpeter Taken Prisoner\n",
      "The Two Pots\n",
      "The Vain Jackdaw\n",
      "The Wolf and the Crane\n",
      "The Wolf and the Lamb\n",
      "The Wolf in Sheep's Clothing\n"
     ]
    }
   ],
   "source": [
    "fables_alt = json.load(open(file))\n",
    "for f in fables_alt: print(f['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['antgrass2.ram', 'TheAssandhisPurchaser2', 'TheAssandtheLapdog2', 'TheAssintheLionSkin', 'TheBellyandtheMembers2', 'TheBuffoonandtheCountryman', 'TheCrowandthePitcher2', 'TheDogintheManger2', 'TheDogandtheShadow2', 'TheEagleandtheArrow2', 'TheFoxandtheCrow2', 'TheFoxandtheGoat2', 'TheFoxandtheGrapes2', 'TheFoxandtheLion', 'TheFoxandtheMask', 'haretort2.ram', 'harefrog2.ram', 'TheHorseandtheAss2', 'TheLionandtheMouse2', 'TheLioninLove2', 'TheManandtheSatyr2', 'MercuryandtheWoodman', 'milkpail2.ram', 'TheOldManandDeath2', 'TheOldWomanandtheWine-Jar', 'TheOne-EyedDoe', 'ThePeacockandJuno', 'TheRoseandtheAmaranth', 'TheSerpentandtheEagle', 'shepherd2.ram', 'TheSickLion2', 'TheTownMouseandtheCountryMouse', 'TheTrumpeterTakenPrisoner2', 'TheTwoPots2', 'TheVainJackdaw', 'TheWolfandtheCrane2', 'TheWolfandtheLamb2', 'TheWolfinSheepsClothing2'])\n"
     ]
    }
   ],
   "source": [
    "tfidf_alt = tf_idfs(fables_alt)\n",
    "print(tfidf_alt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write a function `most_similar()` that takes a spare vector representation of a document and find the most similar fable among the ones in [aesopfables.json](https://github.com/emory-courses/computational-linguistics/blob/master/res/vsm/aesopfables.json).\n",
    "\n",
    "```python\n",
    "def most_similar(Y: Dict[str, Dict[str, float]], x: Dict[str, float]) -> str:\n",
    "    # To be filled\n",
    "    return ''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antgrass2.ram -> TheAntsandtheGrasshopper\n",
      "TheAssandhisPurchaser2 -> TheAssandHisPurchaser\n",
      "TheAssandtheLapdog2 -> TheAssandtheLapdog\n",
      "TheAssintheLionSkin -> TheAsstheFoxandtheLion\n",
      "TheBellyandtheMembers2 -> TheBellyandtheMembers\n",
      "TheBuffoonandtheCountryman -> TheBuffoonandtheCountryman2\n",
      "TheCrowandthePitcher2 -> crowpitc2.ram\n",
      "TheDogintheManger2 -> TheHeiferandtheOx\n",
      "TheDogandtheShadow2 -> TheDogandtheShadow\n",
      "TheEagleandtheArrow2 -> TheEagleandtheArrow\n",
      "TheFoxandtheCrow2 -> TheFoxandtheCrow\n",
      "TheFoxandtheGoat2 -> TheFoxandtheGoat\n",
      "TheFoxandtheGrapes2 -> TheFoxandtheGrapes\n",
      "TheFoxandtheLion -> TheFoxandtheLion2\n",
      "TheFoxandtheMask -> foxmask2.ram\n",
      "haretort2.ram -> TheHareandtheTortoise\n",
      "harefrog2.ram -> TheHaresandtheFrogs\n",
      "TheHorseandtheAss2 -> TheHorseandtheAss\n",
      "TheLionandtheMouse2 -> lionmouse\n",
      "TheLioninLove2 -> TheLioninLove\n",
      "TheManandtheSatyr2 -> TheManandtheSatyr\n",
      "MercuryandtheWoodman -> MercuryandtheWorkmen\n",
      "milkpail2.ram -> milkmaidjug.jpg\n",
      "TheOldManandDeath2 -> TheFatherandHisSons\n",
      "TheOldWomanandtheWine-Jar -> womanjar2.ram\n",
      "TheOne-EyedDoe -> TheOneEyedDoe\n",
      "ThePeacockandJuno -> ThePeacockandJuno2\n",
      "TheRoseandtheAmaranth -> TheRoseandtheAmaranth2\n",
      "TheSerpentandtheEagle -> TheSerpentandtheEagle2\n",
      "shepherd2.ram -> shepwolf2.ram\n",
      "TheSickLion2 -> TheLiontheFoxandtheBeasts\n",
      "TheTownMouseandtheCountryMouse -> TheTownMouseandtheCountryMouse2\n",
      "TheTrumpeterTakenPrisoner2 -> TheTrumpeterTakenPrisoner\n",
      "TheTwoPots2 -> twopots2.ram\n",
      "TheVainJackdaw -> TheVainJackdaw2\n",
      "TheWolfandtheCrane2 -> TheWolfandtheCrane\n",
      "TheWolfandtheLamb2 -> TheWolfandtheLamb\n",
      "TheWolfinSheepsClothing2 -> TheWolfandtheShepherd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def magnitude(vec) -> float:\n",
    "    return np.linalg.norm(vec)\n",
    "\n",
    "def buildVector(vec1, vec2):   # shamelessly stolen off stackexchange\n",
    "    counter1 = Counter(vec1)\n",
    "    counter2= Counter(vec2)\n",
    "    all_items = set(counter1.keys()).union( set(counter2.keys()) )\n",
    "    vector1 = np.array([counter1[k] for k in all_items])\n",
    "    vector2 = np.array([counter2[k] for k in all_items])\n",
    "    return vector1, vector2\n",
    "\n",
    "\n",
    "def cos_difference(x,y) -> float:\n",
    "    return np.inner(x,y) / (magnitude(x) * magnitude(y))\n",
    "\n",
    "def most_similar(Y: dict[str, dict[str, float]], x: dict[str, float]) -> str:\n",
    "    most_simliar_so_far = ['Androcles', 0]\n",
    "    for fable in Y:\n",
    "        hell,yeah = buildVector(x, Y[fable])\n",
    "        if cos_difference(hell,yeah) >= most_simliar_so_far[1]:\n",
    "            most_simliar_so_far[0] = fable\n",
    "            most_simliar_so_far[1] = cos_difference(hell, yeah)\n",
    "\n",
    "    return most_simliar_so_far[0]\n",
    "\n",
    "for k, x in tfidf_alt.items():\n",
    "    t = most_similar(tfidfs, x)\n",
    "    print('{} -> {}'.format(k, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
